{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from alphabet import Alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "alefs = [ \"ا\", \"أ\", \"آ\", \"إ\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = ' ABCDEFGHIJKLMNOPQRSTUVWXYZÀÁÂÃÄÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖ×ØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõö÷øùúûüýþÿĀāĂăĄąĆćĈĉĊċČčĎďĐđĒēĔĕĖėĘęĚěĜĝĞğĠġĢģĤ0123456789!\"%(),./:=?[]«»،؛؟-+*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = {}\n",
    "letters_positions={}\n",
    "with open('letters.csv','r', encoding='utf-8') as inf:\n",
    "    for line in inf:\n",
    "        key,val=line.split(',')\n",
    "        letters[key]=val.strip()\n",
    "letters[',']=','\n",
    "with open('letters_positions.csv','r', encoding='utf-8') as inf:\n",
    "    for idx,line in enumerate(inf):       \n",
    "        letters_positions[line.strip()]=idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_two_pos(txt):\n",
    "    return txt in  [ \"أ\", \"ا\", \"إ\", \"آ\", \"ؤ\", \"د\", \"ذ\", \"ر\", \"ز\", \"و\", \"ة\", \"ء\", \"لا\", \"لأ\", \"لآ\", \"لإ\",\"ا\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_isoleted(txt):\n",
    "    return txt in ['0','1','2','3','4','5','6','7','8','9','!','\"','%','(',')',',','.','/',':','=','?','[',']','«','»','،','؛','؟','–','+',' ','ء','.',',',':',' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_letter_position( cur,  pre =None, nex = None):\n",
    "    if pre == None and nex==None:\n",
    "        return ''\n",
    "    if is_isoleted(cur):\n",
    "        return ''\n",
    "    if is_two_pos(cur):\n",
    "        if is_two_pos(pre) or pre == None or is_isoleted(pre):\n",
    "            return ''\n",
    "        else:\n",
    "            return \"_E\"\n",
    "    else:\n",
    "        if pre != None and nex!=None and not is_two_pos(pre) and not is_isoleted(nex) and not is_isoleted(pre):\n",
    "            return '_M'\n",
    "        elif (pre == None or is_isoleted(pre)   or is_two_pos(pre)  ) and (nex != None and not is_isoleted(nex)  ):\n",
    "            return '_S'\n",
    "        elif (nex ==None or  is_isoleted(nex) ) and not (is_two_pos(pre) or is_isoleted(pre) ):\n",
    "            return '_E'\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "text='« = امن بة كثير من الرجال والنساء والغلام'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2label(text): \n",
    "    encoded=''\n",
    "    pre=None\n",
    "    nex=None\n",
    "    cont=False\n",
    "    if len(text)==1:\n",
    "        encoded=chars[letters_positions[letters[text]]]\n",
    "        return encoded\n",
    "    for idx,cur in enumerate(text):    \n",
    "        if cont:\n",
    "            cont=False\n",
    "            continue\n",
    "        if(len(text)==1):\n",
    "            print(letters_positions[letters[text]])\n",
    "        if idx == 0 :\n",
    "            pre=None\n",
    "            nex=text[idx+1]\n",
    "        elif idx==len(text)-1:\n",
    "            pre=text[idx-1]\n",
    "            nex=None\n",
    "        else:\n",
    "            pre=text[idx-1]\n",
    "            nex=text[idx+1]\n",
    "            \n",
    "        if cur=='ل' and nex in alefs:\n",
    "            cur=cur+nex\n",
    "            cont=True\n",
    "            if idx+1==len(text)-1:\n",
    "                nex=None\n",
    "            else:\n",
    "                nex=text[idx+2]\n",
    "        encoded=encoded+chars[letters_positions[letters[cur] + get_letter_position(cur, pre, nex)]]\n",
    "    return encoded\n",
    "    #     print('pre:'+str(pre)+',cur:'+cur+',nex:'+str(nex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' NĈĎ QU ĀÁěÔ ĈĎ NĄÔÄOă ēNĄčÙOA ēNĄõĞć'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2label(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('labels.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labels']=df['text'].apply(lambda x:text2label(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.txt</td>\n",
       "      <td>ذهب احمد الى المدرسة</td>\n",
       "      <td>ÑĐS NÈĉÐ NĄĘ NĄĉÐÓØU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.txt</td>\n",
       "      <td>الانسان</td>\n",
       "      <td>NĝČÙOċ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.txt</td>\n",
       "      <td>اللغة العربية</td>\n",
       "      <td>NĄąõU NĄñÔQěU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  file_name                  text                labels\n",
       "0     1.txt  ذهب احمد الى المدرسة  ÑĐS NÈĉÐ NĄĘ NĄĉÐÓØU\n",
       "1     2.txt               الانسان                NĝČÙOċ\n",
       "2     3.txt         اللغة العربية         NĄąõU NĄñÔQěU"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44, 107, 19, 0, 14, 35, 100, 43, 0, 14, 95, 115, 0, 14, 95, 100, 43, 46, 51, 21]\n",
      "[14, 120, 103, 52, 15, 102]\n",
      "[14, 95, 96, 80, 21, 0, 14, 95, 76, 47, 17, 118, 21]\n"
     ]
    }
   ],
   "source": [
    "# create target inputs\n",
    "#write labels to files to be placed as pairs with feature file e.g  1_input.npy  as feature and 1_target.npy as label\n",
    "alphabet=Alphabet('alphabet.txt')\n",
    "for idx,row in df.iterrows():\n",
    "    print(alphabet.encode(row['labels']))\n",
    "    np.save('data/'+row['file_name'].replace('.txt','_target.npy'),alphabet.encode(row['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_features import process_single_file\n",
    "from lang_trans.arabic import buckwalter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"../OnlineKHATTData/Training/\"\n",
    "train_save = \"onlineKhatt/train\"\n",
    "val_data_path = \"../OnlineKHATTData/Validation/\"\n",
    "dev_save = \"onlineKhatt/dev\"\n",
    "test_save = \"onlineKhatt/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backwalter_labels = [\"'\", \"|\", \">\", \"&\", \"<\", \"}\", \"A\", \"b\", \"p\", \"t\", \"v\", \"j\", \"H\", \"x\", \"d\", \"*\",\n",
    "                  \"r\", \"z\", \"s\", \"$\", \"S\", \"D\", \"T\", \"Z\", \"E\", \"g\", \"_\", \"f\", \"q\", \"k\",  \"l\", \"m\", \n",
    "                    \"n\", \"h\", \"w\", \"Y\", \"y\", \"F\", \"N\", \"K\", \"a\", \"u\", \"i\",  \"~\", \"o\", \"`\", \"{\", \"P\",\n",
    "                    \"J\", \"V\", \"G\", \"#\", \" \"]\n",
    "with open(\"backwalter_labels.txt\",\"w\") as f:\n",
    "    f.writelines(\"\\n\".join(backwalter_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data input\n",
    "ink_paths = list(Path(train_data_path).glob(\"*_coor.txt\"))\n",
    "save_dir = Path(train_save)\n",
    "os.makedirs(save_dir,exist_ok=True)\n",
    "print(len(ink_paths))\n",
    "for filename in ink_paths :\n",
    "        with open(filename) as file:\n",
    "            process_single_file(file,filename, f'{save_dir}/{filename.stem}_input.npy', normalize=True)\n",
    "            file.close()\n",
    "            try:\n",
    "                os.rename(filename,'processed/'+filename)\n",
    "            except Exception as e:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create target inputs\n",
    "alphabet=Alphabet('backwalter_labels.txt')\n",
    "text_target_path = list(Path(train_data_path).glob(\"*.txt\"))\n",
    "save_dir = Path(train_save)\n",
    "os.makedirs(save_dir,exist_ok=True)\n",
    "for file_name in text_target_path:\n",
    "    # print(alphabet.encode(row['labels']))\n",
    "    # np.save(str(save_dir)+'/'+file_name.replace('.txt','_target.npy'), alphabet.encode(row['labels']))\n",
    "    unicode = ['\\ufeff','\\xa0','،','–','‐','؛',',','\"','؟','\\n','‘','/','%']\n",
    "    if \"coor\" not in file_name.name:\n",
    "        with open(file_name,'r') as f:\n",
    "            text = f.read()\n",
    "            for i in unicode:\n",
    "                if i in text:\n",
    "                    text= text.replace(i,' ')\n",
    "        label = buckwalter.transliterate(text.strip())\n",
    "        np.save(str(save_dir)+'/'+ file_name.name.replace('.txt','_target.npy'), alphabet.encode(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data input\n",
    "ink_paths = list(Path(val_data_path).glob(\"*_coor.txt\"))\n",
    "save_dir = Path(val_save)\n",
    "os.makedirs(save_dir,exist_ok=True)\n",
    "print(len(ink_paths))\n",
    "for filename in ink_paths :\n",
    "        with open(filename) as file:\n",
    "            process_single_file(file,filename, f'{save_dir}/{filename.stem}_input.npy', normalize=True)\n",
    "            file.close()\n",
    "            try:\n",
    "                os.rename(filename,'processed/'+filename)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "# create target inputs\n",
    "alphabet=Alphabet('backwalter_labels.txt')\n",
    "text_target_path = list(Path(val_data_path).glob(\"*.txt\"))\n",
    "save_dir = Path(val_save)\n",
    "os.makedirs(save_dir,exist_ok=True)\n",
    "for file_name in text_target_path:\n",
    "    # print(alphabet.encode(row['labels']))\n",
    "    # np.save(str(save_dir)+'/'+file_name.replace('.txt','_target.npy'), alphabet.encode(row['labels']))\n",
    "    unicode = ['\\ufeff','\\xa0','،','–','‐','؛',',','\"','؟','\\n','‘']\n",
    "    if \"coor\" not in file_name.name:\n",
    "        with open(file_name,'r') as f:\n",
    "            text = f.read()\n",
    "            for i in unicode:\n",
    "                if i in text:\n",
    "                    text= text.replace(i,' ')\n",
    "        label = buckwalter.transliterate(text.strip())\n",
    "        np.save(str(save_dir)+'/'+ file_name.name.replace('.txt','_target.npy'), alphabet.encode(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3066\n"
     ]
    }
   ],
   "source": [
    "val_files = os.listdir(val_save)\n",
    "print(len(val_files))\n",
    "val_files_names = [f.rsplit('_',1)[0] for f in val_files if \"coor\" not in f]\n",
    "shuffle(val_files_names)\n",
    "partition = len(val_files_names) // 2 + 1\n",
    "val_files, test_files = val_files_names[:partition], val_files_names[partition:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move test files under test dir\n",
    "# change val to dev\n",
    "import shutil\n",
    "for file in test_files:\n",
    "    shutil.move(os.path.join(val_save,file+\"_input.npy\"),os.path.join(test_save,file+\"_input.npy\"))\n",
    "    shutil.move(os.path.join(val_save,file+\"_target.npy\"),os.path.join(test_save,file+\"_target.npy\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = test_save\n",
    "for file in os.listdir(data_dir):\n",
    "    if \"_coor\" in file:\n",
    "        os.rename(os.path.join(data_dir,file), os.path.join(data_dir,file.replace('_coor','')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"« = Amn bp kvyr mn AlrjAl wAlnsA' wAlglAm\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buckwalter.transliterate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'« = امن بة كثير من الرجال والنساء والغلام'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "da81d1f547c2b9bcaba1322708217f7f1724358285b2f117b9216fc22b29a70b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('khatt_1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
